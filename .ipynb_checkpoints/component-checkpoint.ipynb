{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modified_gru():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_steps,init_state,scalar_values,input_size,\n",
    "                 output_size,final_mem,question,input_seq=None):\n",
    "        \n",
    "        # inputs required for sequential memory vectors e_i \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input ideally zero tensor\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.scalar_values = scalar_values        # gated scalar values \n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # inputs required for Answer modules\n",
    "        self.question = question\n",
    "        self.final_mem = final_mem\n",
    "        self.word_weight = tf.get_variable(\"word_w\",[output_size,output_size],dtype=tf.float64)\n",
    "        self.word_bias = tf.get_variable(\"word_b\",[output_size,1],dtype=tf.float64)\n",
    "#         self.init_word = init_word          # should be ideally a zero vector\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w\",[output_size,input_size],dtype=tf.float64),tf.get_variable(\"reset_w\",[output_size,input_size],dtype=tf.float64),tf.get_variable(\"out_w\",[output_size,input_size],dtype=tf.float64)\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u\",[output_size,output_size],dtype=tf.float64),tf.get_variable(\"reset_u\",[output_size,output_size],dtype=tf.float64),tf.get_variable(\"out_u\",[output_size,output_size],dtype=tf.float64)\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b\",[output_size,1],dtype=tf.float64),tf.get_variable(\"reset_b\",[output_size,1],dtype=tf.float64),tf.get_variable(\"out_b\",[output_size,1],dtype=tf.float64)\n",
    "    \"\"\"\n",
    "    right now its a normal gru !!!\n",
    "    You need to change the the output !!!\n",
    "    \"\"\"\n",
    "    def mod_gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z,name=\"matmul_2\")\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        h_t = (self.scalar_values[index]*h_t) + ((1-self.scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.mod_gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "        \n",
    "    def answer_gru_unit(self,h_prev,word_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "#         print(np.shape(word_prev),np.shape(self.question))\n",
    "        input_vector = tf.concat([word_prev,self.question],axis=0)\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector,name = 'matmul_1')+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        word_pred = tf.nn.softmax(tf.matmul(self.word_weight,h_t)+self.word_bias)\n",
    "#         print(h_t)\n",
    "#         print(word_pred)\n",
    "        out.append(word_pred)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.answer_gru_unit(h_prev = h_t,word_prev = word_pred,out = out,steps = steps) \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Softmax:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_1:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_2:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_3:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_4:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_5:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_6:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_7:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_8:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'Softmax_9:0' shape=(20, 1) dtype=float64>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "gru = modified_gru(time_steps = 10,\n",
    "                   init_state = np.random.random(size=(20,1)),\n",
    "                   input_seq = np.random.random(size=(10,40,1)),\n",
    "                   scalar_values = np.random.random(size=(10,1)),\n",
    "                   input_size = 40,\n",
    "                   output_size = 20,\n",
    "                   question = np.random.random(size=(20,1)),\n",
    "                   final_mem = np.random.random(size=(20,1)))\n",
    "gru.answer_gru_unit(h_prev=np.random.random(size=(20,1)),\n",
    "                    word_prev = gru.init_state,\n",
    "                    steps = gru.time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'add_7:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_15:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_23:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_31:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_39:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_47:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_55:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_63:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_71:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Tensor 'add_79:0' shape=(20, 1) dtype=float64>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "gru = modified_gru(time_steps = 10,\n",
    "                   init_state = np.random.random(size=(20,1)),\n",
    "                   input_seq = np.random.random(size=(10,20,1)),\n",
    "                   scalar_values = np.random.random(size=(10,1)),\n",
    "                   input_size = 20,\n",
    "                   output_size = 20,\n",
    "                   question = np.random.random(size=(20,1)),\n",
    "                   final_mem = np.random.random(size=(20,1)))\n",
    "gru.mod_gru_unit(steps = gru.time_steps,h_prev=gru.init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
