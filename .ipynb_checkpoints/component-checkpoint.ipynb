{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modified_gru():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_step,init_state,input_seq,scalar_values):\n",
    "        \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.scalar_values = scalar_values        # gated scalar values \n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w\",[output_size,input_size]),tf.get_variable(\"reset_w\",[output_size,input_size]),tf.get_variable(\"out_w\",[input_size,output_size])\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u\",[input_size,output_size]),tf.get_variable(\"reset_u\",[input_size,output_size]),tf.get_variable(\"out_u\",[output_size,output_size])\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b\",[output_size]),tf.get_variable(\"reset_b\",[output_size]),tf.get_variable(\"out_b\",[output_size])\n",
    "        \n",
    "    \"\"\"\n",
    "    right now its a normal gru !!!\n",
    "    You need to change the the output !!!\n",
    "    \"\"\"\n",
    "    def gru_unit(self,h_prev,out=[],steps = self.time_steps):\n",
    "        index = steps - self.timesteps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.mul(z_t,h_prev)+tf.mul(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(tf.mul(r_t,h_prev))+self.b_h))\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "    \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 10\n",
    "input_size = 10\n",
    "time_step = 1\n",
    "def mod_GRU(cell,scalars,concepts):\n",
    "    OUT = []\n",
    "    for i,j in zip(scalars,concepts):\n",
    "        rnn_input = tf.unstack(i,axis = 1)\n",
    "        print(j)\n",
    "        out,_ = tf.nn.static_rnn(cell,rnn_input,dtype=tf.float32)\n",
    "        OUT.append(out)\n",
    "    return OUT\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-c803bbea6b16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod_GRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     feed_dict = {concepts : np.random.random(size = (10,10)),\n\u001b[0;32m      9\u001b[0m                  scalars : np.random.random(size = (10))}\n",
      "\u001b[1;32m<ipython-input-49-06e9b5529f6a>\u001b[0m in \u001b[0;36mmod_GRU\u001b[1;34m(cell, scalars, concepts)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmod_GRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mOUT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcepts\u001b[0m\u001b[1;31m#tf.unstack(i,axis = 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\princ3\\anaconda3\\envs\\tfconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m       raise TypeError(\n\u001b[1;32m--> 431\u001b[1;33m           \u001b[1;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[0;32m    433\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "concepts = tf.placeholder(dtype=tf.float32,shape=[None,time_step,input_size])\n",
    "scalars = tf.placeholder(dtype=tf.float32,shape=[None,time_step,input_size])\n",
    "cell = tf.nn.rnn_cell.GRUCell(num_units = output_size)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out = mod_GRU(cell,scalars,concepts)\n",
    "    feed_dict = {concepts : np.random.random(size = (10,10)),\n",
    "                 scalars : np.random.random(size = (10))}\n",
    "    \n",
    "    OUT = sess.run(out,feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var_0:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_1:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_2:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_3:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_4:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_5:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_6:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_7:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_8:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'var_9:0' shape=(1, 2, 3) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x =[]\n",
    "for i in range(10):\n",
    "    x.append(tf.get_variable(\"var_{}\".format(i),[1,2,3]))\n",
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 7\n",
      "3 6\n",
      "4 5\n",
      "4 5\n",
      "3 6\n",
      "2 7\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7]#np.random.random(size=(10,2))\n",
    "for i in range(1,len(x)):\n",
    "    print(x[i],x[-i])\n",
    "    x[i],x[-i] = x[-i],x[i]\n",
    "print(x)\n",
    "#     print(x[:-i],'cropped {}'.format(x[-i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
