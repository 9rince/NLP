{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\princ3\\anaconda3\\envs\\tfconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = Word2Vec.load('model.bin')    # word embedding\n",
    "# char_vec = Word2Vec.load('model_c.bin')  # charector embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contxt = pd.read_pickle('./input/squad_contxt.pkl') # context\n",
    "df_qas = pd.read_pickle('./input/squad_qas.pkl')       # question and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep_data():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,contxt = df_contxt,qas = df_qas, word_e = word_vec):\n",
    "        \n",
    "        self.contxt = contxt\n",
    "        self.qas = qas\n",
    "        self.char_e = char_e\n",
    "        self.word_e = word_e\n",
    "\n",
    "    def C2V(self,passage):   # this function converts context 2 vector with <EOS> tag\n",
    "        tb_p = TextBlob(passage)\n",
    "        p2v = []\n",
    "        for i in tb_p.sentences:\n",
    "            words = TextBlob(str(i)+\" E-O-S\").words\n",
    "            for j in words:\n",
    "                p2v.append(word_vec[j])\n",
    "        return np.array(p2v)\n",
    "    \n",
    "    def QA2V(self,question_no):  # this function converts question 2 vector\n",
    "        tb_a = TextBlob(self)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_models():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_steps,init_state,input_size,tag,\n",
    "                 output_size,question=None,final_mem=None,input_seq=None):\n",
    "        \n",
    "        # inputs required for sequential memory vectors e_i \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input ideally zero tensor\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # inputs required for Answer modules\n",
    "        self.question = question\n",
    "        self.final_mem = final_mem\n",
    "        self.word_weight = tf.get_variable(\"word_w_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.word_bias = tf.get_variable(\"word_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"reset_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"out_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64)\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"reset_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"out_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"reset_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"out_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "    \n",
    "    \"\"\" Normal GRU unit \"\"\"\n",
    "    def gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations \n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "#         h_t = (self.scalar_values[index]*h_t) + ((1-self.scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    it's a modified GRU !!!\n",
    "    \"\"\"\n",
    "    def mod_gru_unit(self,h_prev,steps,scalar_values,out=[]):\n",
    "        print(steps,self.time_steps)\n",
    "        index = steps - self.time_steps \n",
    "#         print(index)\n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        h_t = (scalar_values[index]*h_t) + ((1-scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.mod_gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "        \n",
    "    \"\"\" It's a hybrid GRU for answer module \"\"\"\n",
    "    def answer_gru_unit(self,h_prev,word_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        print(index)\n",
    "#         print(np.shape(word_prev),np.shape(self.question))\n",
    "        input_vector = tf.concat([word_prev,self.question],axis=0)\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        word_pred = tf.nn.softmax(tf.matmul(self.word_weight,h_t)+self.word_bias)\n",
    "#         print(h_t)\n",
    "#         print(word_pred)\n",
    "        out.append(word_pred)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.answer_gru_unit(h_prev = h_t,word_prev = word_pred,out = out,steps = steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMN_QA():\n",
    "    \"\"\"\n",
    "    the word vectors have size 100\n",
    "    the max no of words in a sentence is 120\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.MAX_P_WORDS = 120       # max no of words in a passage\n",
    "        self.WORD_VEC_LEN = 100      # word vector length\n",
    "        self.MAX_Q_WORDS = 10        # max no of words in question\n",
    "        self.MAX_NO_CONCEPTS = 5      # max no of concepts\n",
    "        \n",
    "        # variables and placeholders\n",
    "        self.Passage = tf.placeholder(shape=(self.MAX_P_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64)\n",
    "        self.EOS_Tag = tf.placeholder(tf.float64)\n",
    "        self.Question = tf.placeholder(shape=(self.MAX_Q_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64) #sequence for question\n",
    "        self.Answer = tf.placeholder(tf.float64)\n",
    "        \n",
    "        # weigts for scalar kernel and memory vector\n",
    "        self.W_b = tf.get_variable(\"W_b\",shape=(100,100),dtype=tf.float64)\n",
    "        self.W_1 = tf.get_variable(\"W_1\",shape=(200,702),dtype=tf.float64)\n",
    "        self.b_1 = tf.get_variable(\"b_1\",shape=(200,1),dtype=tf.float64)\n",
    "        self.W_2 = tf.get_variable(\"W_2\",shape=(1,200),dtype=tf.float64)\n",
    "        self.b_2 = tf.get_variable(\"b_2\",shape=(1,1),dtype=tf.float64)\n",
    "        \n",
    "        # initial memory state\n",
    "        self.memory = tf.placeholder(shape=(100,1),dtype=tf.float64)\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        # question module \n",
    "        Q_module = gru_models(time_steps=self.MAX_Q_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Question,tag=1)\n",
    "        Q_out = Q_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_Q_WORDS,out=[])\n",
    "        \n",
    "        self.question = Q_out[-1] # final representation of question\n",
    "        #passage module\n",
    "        P_module = gru_models(time_steps=self.MAX_P_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Passage,tag=2)\n",
    "        P_out = P_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_P_WORDS,out=[])\n",
    "        print(len(P_out))\n",
    "        #episodic memory module\n",
    "        concepts = P_out[:3]  # selected E-O-S tags from P_out\n",
    "        epi_mod = gru_models(time_steps=self.MAX_P_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Passage,tag=3)\n",
    "        y = self.epi_mem_mod(concepts,len(concepts),epi_mod,[])\n",
    "        return y\n",
    "    \n",
    "    def epi_mem_mod(self,concepts,no_of_iterations,mode,mem_states=[]):\n",
    "        scalar_vector = []\n",
    "        for i in concepts:\n",
    "            scalar_vector.append(self.scalar_gate_value(i))\n",
    "        \n",
    "        concepts_out = mode.mod_gru_unit(h_prev = self.memory,steps=len(concepts),scalar_values=scalar_vector,\n",
    "                          out=[])\n",
    "        self.memory = concepts_out[-1]\n",
    "        mem_states.append(concepts_out[-1])\n",
    "        if no_of_iterations == 0:\n",
    "            return mem_states\n",
    "        else:\n",
    "            self.epi_mem_mod(concepts,no_of_iterations-1,\n",
    "                        mode,mem_states)\n",
    "            \n",
    "    def scalar_gate_value(self,concept):\n",
    "        z_vector = tf.concat((concept,self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.question)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.memory)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.question))),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.memory))),axis=0)\n",
    "        g_1 =  tf.nn.relu(tf.add(tf.matmul(self.W_1,z_vector),self.b_1))\n",
    "        print(g_1)\n",
    "        g_scalar =  tf.nn.relu(tf.add(tf.matmul(self.W_2,g_1),self.b_2))\n",
    "        print(g_scalar)\n",
    "        return g_scalar\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "Tensor(\"Relu:0\", shape=(200, 1), dtype=float64)\n",
      "Tensor(\"Relu_1:0\", shape=(1, 1), dtype=float64)\n",
      "Tensor(\"Relu_2:0\", shape=(200, 1), dtype=float64)\n",
      "Tensor(\"Relu_3:0\", shape=(1, 1), dtype=float64)\n",
      "Tensor(\"Relu_4:0\", shape=(200, 1), dtype=float64)\n",
      "Tensor(\"Relu_5:0\", shape=(1, 1), dtype=float64)\n",
      "-117\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-e571fe1b04ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMN_QA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-9b069b0862bd>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m         epi_mod = gru_models(time_steps=self.MAX_P_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n\u001b[0;32m     45\u001b[0m                               input_size=100,output_size=100,input_seq=self.Passage,tag=3)\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepi_mem_mod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepi_mod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-9b069b0862bd>\u001b[0m in \u001b[0;36mepi_mem_mod\u001b[1;34m(self, concepts, no_of_iterations, mode, mem_states)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         concepts_out = mode.mod_gru_unit(h_prev = self.memory,steps=len(concepts),scalar_values=scalar_vector,\n\u001b[1;32m---> 55\u001b[1;33m                           out=[])\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcepts_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mmem_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcepts_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-b6385a8aaaa7>\u001b[0m in \u001b[0;36mmod_gru_unit\u001b[1;34m(self, h_prev, steps, scalar_values, out)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mh_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mh_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscalar_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscalar_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_steps\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = DMN_QA()\n",
    "    y = x.build()\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA2V(context_no,question_no):\n",
    "    passage = TextBlob(df_contxt['context'][context_no])\n",
    "    question = TextBlob(df_qas['Question'][question_no])\n",
    "    if df_qas['is_impossible'][question_no]==False:\n",
    "        answer = TextBlob(df_qas['Answer_text'][question_no])\n",
    "        beginning = passage[:df_qas['Answer_start'][question_no]]\n",
    "        end = passage[df_qas['Answer_start'][question_no]+len(answer):]  # verified\n",
    "        \n",
    "        \n",
    "#         print(answer.words,'\\n',len(answer.words),'\\n',len(beginning.words),'\\n',len(end.words))\n",
    "    print(len(passage.words),'\\n',len(beginning.words),'\\n',len(answer.words),'\\n',len(end.words))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA2V(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob(str(TextBlob(df_contxt['context'][1]).sentences[0])+\" E-O-S\").words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(value=np.random.random(size=(100,1)),shape=(100,1))\n",
    "y = tf.constant(value=np.random.random(size=(100,1)),shape=(100,1))\n",
    "z = tf.tensordot(tf.transpose(x),y,axes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Tensordot_3:0' shape=(1, 1) dtype=float64>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
