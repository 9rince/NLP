{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\princ3\\anaconda3\\envs\\tfconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = Word2Vec.load('model.bin')    # word embedding\n",
    "# char_vec = Word2Vec.load('model_c.bin')  # charector embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contxt = pd.read_pickle('./input/squad_contxt.pkl') # context\n",
    "df_qas = pd.read_pickle('./input/squad_qas.pkl')       # question and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep_data():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,contxt = df_contxt,qas = df_qas, word_e = word_vec):\n",
    "        \n",
    "        self.contxt = contxt\n",
    "        self.qas = qas\n",
    "        self.char_e = char_e\n",
    "        self.word_e = word_e\n",
    "\n",
    "    def C2V(self,passage):   # this function converts context 2 vector with <EOS> tag\n",
    "        tb_p = TextBlob(passage)\n",
    "        p2v = []\n",
    "        for i in tb_p.sentences:\n",
    "            words = TextBlob(str(i)+\" E-O-S\").words\n",
    "            for j in words:\n",
    "                p2v.append(word_vec[j])\n",
    "        return np.array(p2v)\n",
    "    \n",
    "    def QA2V(self,question_no):  # this function converts question 2 vector\n",
    "        tb_a = TextBlob(self)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_models():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_steps,init_state,input_size,\n",
    "                 output_size,question=None,final_mem=None,input_seq=None,scalar_values=None):\n",
    "        \n",
    "        # inputs required for sequential memory vectors e_i \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input ideally zero tensor\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.scalar_values = scalar_values        # gated scalar values \n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # inputs required for Answer modules\n",
    "        self.question = question\n",
    "        self.final_mem = final_mem\n",
    "        self.word_weight = tf.get_variable(\"word_w\",[output_size,output_size],dtype=tf.float64)\n",
    "        self.word_bias = tf.get_variable(\"word_b\",[output_size,1],dtype=tf.float64)\n",
    "#         self.init_word = init_word          # should be ideally a zero vector\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w\",[output_size,input_size],dtype=tf.float64),tf.get_variable(\"reset_w\",[output_size,input_size],dtype=tf.float64),tf.get_variable(\"out_w\",[output_size,input_size],dtype=tf.float64)\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u\",[output_size,output_size],dtype=tf.float64),tf.get_variable(\"reset_u\",[output_size,output_size],dtype=tf.float64),tf.get_variable(\"out_u\",[output_size,output_size],dtype=tf.float64)\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b\",[output_size,1],dtype=tf.float64),tf.get_variable(\"reset_b\",[output_size,1],dtype=tf.float64),tf.get_variable(\"out_b\",[output_size,1],dtype=tf.float64)\n",
    "    \n",
    "    \"\"\" Normal GRU unit \"\"\"\n",
    "    def gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations \n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z,name=\"matmul_2\")\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "#         h_t = (self.scalar_values[index]*h_t) + ((1-self.scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    it's a modified GRU !!!\n",
    "    \"\"\"\n",
    "    def mod_gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z,name=\"matmul_2\")\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        h_t = (self.scalar_values[index]*h_t) + ((1-self.scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.mod_gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "        \n",
    "    \"\"\" It's a hybrid GRU for answer module \"\"\"\n",
    "    def answer_gru_unit(self,h_prev,word_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "#         print(np.shape(word_prev),np.shape(self.question))\n",
    "        input_vector = tf.concat([word_prev,self.question],axis=0)\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector,name = 'matmul_1')+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        word_pred = tf.nn.softmax(tf.matmul(self.word_weight,h_t)+self.word_bias)\n",
    "#         print(h_t)\n",
    "#         print(word_pred)\n",
    "        out.append(word_pred)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.answer_gru_unit(h_prev = h_t,word_prev = word_pred,out = out,steps = steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMN_QA():\n",
    "    \"\"\"\n",
    "    the word vectors have size 100\n",
    "    the max no of words in a sentence is 120\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.MAX_P_WORDS = 120\n",
    "        self.WORD_VEC_LEN = 100\n",
    "        self.MAX_Q_WORDS = 10\n",
    "        \n",
    "        # variables and placeholders\n",
    "        self.Passage = tf.placeholder(tf.float64)\n",
    "        self.EOS_Tag = tf.placeholder(tf.float64)\n",
    "        self.Question = tf.placeholder(tf.float64)\n",
    "        self.Answer = tf.placeholder(tf.float64)\n",
    "        \n",
    "        # weigts for scalar kernel and memory vector\n",
    "#         self.W_b = tf.Variable(tf.float32)\n",
    "#         self.W_1 = tf.Variable(tf.float32)\n",
    "#         self.b_1 = tf.Variable(tf.float32)\n",
    "#         self.W_2 = tf.Variable(tf.float32)\n",
    "#         self.b_2 = tf.Variable(tf.float32)\n",
    "        \n",
    "        # initial memory state\n",
    "        self.memory = self.Question\n",
    "    \n",
    "    def build(self):\n",
    "        #tf.reset_default_graph()\n",
    "        \n",
    "        # question module \n",
    "        Q_module = gru_models(time_steps=self.MAX_Q_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Question)\n",
    "        Q_out = Q_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_Q_WORDS,out=[])\n",
    "\n",
    "        #passage module\n",
    "              \n",
    "        return Q_out\n",
    "    \n",
    "    \n",
    "        \n",
    "    def scalar_gate_value(self,concept):\n",
    "        \n",
    "        z_vector = tf.concat(concept,self.memory)\n",
    "        z_vector = tf.concat(z_vector,self.question)\n",
    "        z_vector = tf.concat(z_vector,tf.multiply(concept,self.question))\n",
    "        z_vector = tf.concat(z_vector,tf.multiply(concept,memory))\n",
    "        z_vector = tf.concat(z_vector,tf.subtract(concept-self.question))\n",
    "        z_vector = tf.concat(z_vector,tf.subtract(concept-self.memory))\n",
    "        z_vector = tf.concat(z_vector,tf.tensordot(concept,tf.matmul(self.W_b,self.question)))\n",
    "        z_vector = tf.concat(z_vector,tf.tensordot(concept,tf.matmul(self.W_b,self.memory)))\n",
    "        g_1 =  tf.nn.relu(tf.add(tf.matmul(self.W_1,z_vector),self.b_1))\n",
    "        g_scalar =  tf.nn.relu(tf.add(tf.matmul(self.W_2,g1),self.b_2))\n",
    "        \n",
    "        return g_scalar\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = DMN_QA()\n",
    "    y = x.build()\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA2V(context_no,question_no):\n",
    "    passage = TextBlob(df_contxt['context'][context_no])\n",
    "    question = TextBlob(df_qas['Question'][question_no])\n",
    "    if df_qas['is_impossible'][question_no]==False:\n",
    "        answer = TextBlob(df_qas['Answer_text'][question_no])\n",
    "        beginning = passage[:df_qas['Answer_start'][question_no]]\n",
    "        end = passage[df_qas['Answer_start'][question_no]+len(answer):]  # verified\n",
    "        \n",
    "        \n",
    "#         print(answer.words,'\\n',len(answer.words),'\\n',len(beginning.words),'\\n',len(end.words))\n",
    "    print(len(passage.words),'\\n',len(beginning.words),'\\n',len(answer.words),'\\n',len(end.words))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 \n",
      " 39 \n",
      " 4 \n",
      " 70\n"
     ]
    }
   ],
   "source": [
    "QA2V(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob(str(TextBlob(df_contxt['context'][1]).sentences[0])+\" E-O-S\").words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 12, 21, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "y = np.array([5,6,7,8])\n",
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
