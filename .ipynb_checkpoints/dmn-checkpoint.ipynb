{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\princ3\\anaconda3\\envs\\tfconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = Word2Vec.load('model.bin')    # word embedding\n",
    "# char_vec = Word2Vec.load('model_c.bin')  # charector embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contxt = pd.read_pickle('./input/squad_contxt.pkl') # context\n",
    "df_qas = pd.read_pickle('./input/squad_qas.pkl')       # question and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep_data():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,contxt = df_contxt,qas = df_qas, word_e = word_vec):\n",
    "        \n",
    "        self.contxt = contxt\n",
    "        self.qas = qas\n",
    "        self.char_e = char_e\n",
    "        self.word_e = word_e\n",
    "\n",
    "    def C2V(self,passage):   # this function converts context 2 vector with <EOS> tag\n",
    "        tb_p = TextBlob(passage)\n",
    "        p2v = []\n",
    "        for i in tb_p.sentences:\n",
    "            words = TextBlob(str(i)+\" E-O-S\").words\n",
    "            for j in words:\n",
    "                p2v.append(word_vec[j])\n",
    "        return np.array(p2v)\n",
    "    \n",
    "    def QA2V(self,question_no):  # this function converts question 2 vector\n",
    "        tb_a = TextBlob(self)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_models():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_steps,init_state,input_size,tag,\n",
    "                 output_size,question=None,final_mem=None,input_seq=None):\n",
    "        \n",
    "        # inputs required for sequential memory vectors e_i \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input ideally zero tensor\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # inputs required for Answer modules\n",
    "        self.question = question\n",
    "        self.final_mem = final_mem\n",
    "        self.word_weight = tf.get_variable(\"word_w_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.word_bias = tf.get_variable(\"word_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"reset_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"out_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64)\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"reset_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"out_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"reset_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"out_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "    \n",
    "    \"\"\" Normal GRU unit \"\"\"\n",
    "    def gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations \n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    it's a modified GRU !!!\n",
    "    \"\"\"\n",
    "    def mod_gru_unit(self,h_prev,steps,scalar_values,out=[],index=0):\n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        h_t = (scalar_values[index]*h_t) + ((1-scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        index += 1\n",
    "        if steps-index == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.mod_gru_unit(h_prev = h_t,out = out,steps = steps,\n",
    "                                     scalar_values=scalar_values,index=index) \n",
    "        \n",
    "    \"\"\" It's a hybrid GRU for answer module \"\"\"\n",
    "    def answer_gru_unit(self,h_prev,word_prev,out=[]):\n",
    "        input_vector = tf.concat([word_prev,self.question],axis=0)\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        word_pred = tf.nn.softmax(tf.matmul(self.word_weight,h_t)+self.word_bias)\n",
    "        out.append(word_pred)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.answer_gru_unit(h_prev = h_t,word_prev = word_pred,out = out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-c015c51a75d9>, line 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-c015c51a75d9>\"\u001b[1;36m, line \u001b[1;32m100\u001b[0m\n\u001b[1;33m    def train_model:\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DMN_QA():\n",
    "    \"\"\"\n",
    "    the word vectors have size 100\n",
    "    the max no of words in a sentence is 120\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.MAX_P_WORDS = 120       # max no of words in a passage\n",
    "        self.WORD_VEC_LEN = 100      # word vector length\n",
    "        self.MAX_Q_WORDS = 10        # max no of words in question\n",
    "        self.MAX_NO_CONCEPTS = 5      # max no of concepts\n",
    "        \n",
    "        # variables and placeholders\n",
    "        self.Passage = tf.placeholder(shape=(self.MAX_P_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64)\n",
    "#         self.EOS_Tag = tf.placeholder(tf.float64)\n",
    "        self.Question = tf.placeholder(shape=(self.MAX_Q_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64) #sequence for question\n",
    "#         self.Answer = tf.placeholder(tf.float64)\n",
    "\n",
    "        # weigts for scalar kernel and memory vector\n",
    "        self.W_b = tf.get_variable(\"W_b\",shape=(100,100),dtype=tf.float64)\n",
    "        self.W_1 = tf.get_variable(\"W_1\",shape=(200,702),dtype=tf.float64)\n",
    "        self.b_1 = tf.get_variable(\"b_1\",shape=(200,1),dtype=tf.float64)\n",
    "        self.W_2 = tf.get_variable(\"W_2\",shape=(1,200),dtype=tf.float64)\n",
    "        self.b_2 = tf.get_variable(\"b_2\",shape=(1,1),dtype=tf.float64)\n",
    "        \n",
    "        # initial memory state\n",
    "        self.memory = tf.placeholder(shape=(100,1),dtype=tf.float64)\n",
    "        \n",
    "        #training parameters\n",
    "        self.no_epoch = 10\n",
    "        self.df_contxt = pd.read_pickle('./input/squad_contxt.pkl') # context\n",
    "        self.df_qas = pd.read_pickle('./input/squad_qas.pkl')       # question and answers\n",
    "        \n",
    "    def scalar_gate_value(self,concept):  # debugged and perfect\n",
    "        z_vector = tf.concat((concept,self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.question)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.memory)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.question))),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.memory))),axis=0)\n",
    "        g_1 =  tf.nn.tanh(tf.add(tf.matmul(self.W_1,z_vector),self.b_1))\n",
    "        g_scalar =  tf.nn.sigmoid(tf.add(tf.matmul(self.W_2,g_1),self.b_2))\n",
    "        return g_scalar\n",
    "        \n",
    "    def epi_mem_mod(self,concepts,no_of_iterations,mode,mem_states=[]): #debugged\n",
    "        self.scalar_vector = []\n",
    "        for i in concepts:\n",
    "            self.scalar_vector.append(self.scalar_gate_value(i))\n",
    "        \n",
    "        concepts_out = mode.mod_gru_unit(h_prev = self.memory,steps=len(concepts),scalar_values=self.scalar_vector,\n",
    "                          out=[])\n",
    "        self.memory = concepts_out[-1]\n",
    "        mem_states.append(concepts_out[-1])\n",
    "\n",
    "        if no_of_iterations != 0:\n",
    "            self.epi_mem_mod(concepts,no_of_iterations-1,\n",
    "                        mode,mem_states)\n",
    "\n",
    "        return mem_states\n",
    "    \n",
    "    def get_sentence_weight(self,q_no):\n",
    "        y = self.df_contxt['context'][self.df_qas['context_no'][q_no]]\n",
    "        c = -1\n",
    "        count = 0\n",
    "        snt_wt = np.zeros(self.MAX_NO_CONCEPTS)\n",
    "        if self.df_qas['is_impossible'][q_no]!= True:\n",
    "            print()\n",
    "            for i in TextBlob(y).sentences:\n",
    "                c += (len(i)+1)\n",
    "                if self.df_qas['Answer_start'][q_no] < c:\n",
    "                    snt_wt[count] = 1.\n",
    "                    break\n",
    "        return snt_wt\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        # question module \n",
    "        Q_module = gru_models(time_steps=self.MAX_Q_WORDS,\n",
    "                              init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,\n",
    "                              input_seq=self.Question,tag=1)\n",
    "        Q_out = Q_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                                  steps=self.MAX_Q_WORDS,out=[])\n",
    "        \n",
    "        self.question = Q_out[-1] # final representation of question\n",
    "        #passage module\n",
    "        P_module = gru_models(time_steps=self.MAX_P_WORDS,\n",
    "                              init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,\n",
    "                              input_seq=self.Passage,tag=2)\n",
    "        P_out = P_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_P_WORDS,out=[])\n",
    "        #episodic memory module\n",
    "        concepts = P_out[:3]  # selected E-O-S tags from P_out\n",
    "        epi_mod = gru_models(time_steps=2,\n",
    "                             init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                             input_size=100,output_size=100,\n",
    "                             input_seq=concepts,tag=3)\n",
    "        self.mem_states = self.epi_mem_mod(concepts,10,epi_mod,[])\n",
    "        \n",
    "        self.output = self.scalar_vector\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def train_model(self):\n",
    "        tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            pred = self.build()\n",
    "            for i in range(self.no_epoch):\n",
    "                c = 0\n",
    "                while c<1000:\n",
    "                    q_no  = np.random.randint(0,10000)\n",
    "                    y,pred = self.get_sentence_weight()\n",
    "                    cost = y-pred\n",
    "                    optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "        \"\"\"\n",
    "        #answer module\n",
    "        A_module = gru_models(time_steps=len(self.mem_states),\n",
    "                              init_state=None,\n",
    "                              question=self.question,\n",
    "                              input_size=200,output_size=100,\n",
    "                              input_seq=self.mem_states,tag=4)\n",
    "        A_out = A_module.answer_gru_unit(h_prev=self.mem_states[-1],\n",
    "                                         word_prev=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                                         out=[]) \n",
    "        \"\"\"\n",
    "                \n",
    "#         print(A_out)       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = DMN_QA()\n",
    "    y = x.build()\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA2V(context_no,question_no):\n",
    "    passage = TextBlob(df_contxt['context'][context_no])\n",
    "    question = TextBlob(df_qas['Question'][question_no])\n",
    "    if df_qas['is_impossible'][question_no]==False:\n",
    "        answer = TextBlob(df_qas['Answer_text'][question_no])\n",
    "        beginning = passage[:df_qas['Answer_start'][question_no]]\n",
    "        end = passage[df_qas['Answer_start'][question_no]+len(answer):]  # verified\n",
    "        print(answer,'\\n',beginning,'\\n',end)\n",
    "    print(len(passage.words),'\\n',len(beginning.words),'\\n',len(answer.words),'\\n',len(end.words))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA2V(1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A self-described \"modern-day feminist\", Beyoncé creates songs that are often characterized by themes of love, relationships, and monogamy, as well as female sexuality and empowerment. On stage, her dynamic, highly choreographed performances have led to critics hailing her as one of the best entertainers in contemporary popular music. Throughout a career spanning 19 years, she has sold over 118 million records as a solo artist, and a further 60 million with Destiny\\'s Child, making her one of the best-selling music artists of all time. She has won 20 Grammy Awards and is the most nominated woman in the award\\'s history. The Recording Industry Association of America recognized her as the Top Certified Artist in America during the 2000s decade. In 2009, Billboard named her the Top Radio Songs Artist of the Decade, the Top Female Artist of the 2000s and their Artist of the Millennium in 2011. Time listed her among the 100 most influential people in the world in 2013 and 2014. Forbes magazine also listed her as the most powerful female musician of 2015.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contxt['context'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé further expanded her acting career, starring as blues singer Etta James in the 2008 musical biopic, Cadillac Records. Her performance in the film received praise from critics, and she garnered several nominations for her portrayal of James, including a Satellite Award nomination for Best Supporting Actress, and a NAACP Image Award nomination for Outstanding Supporting Actress. Beyoncé donated her entire salary from the film to Phoenix House, an organization of rehabilitation centers for heroin addicts around the country. On January 20, 2009, Beyoncé performed James' \"At Last\" at the First Couple's first inaugural ball. Beyoncé starred opposite Ali Larter and Idris Elba in the thriller, Obsessed. She played Sharon Charles, a mother and wife who learns of a woman's obsessive behavior over her husband. Although the film received negative reviews from critics, the movie did well at the US box office, grossing $68 million—$60 million more than Cadillac Records—on a budget of $20 million. The fight scene finale between Sharon and the character played by Ali Larter also won the 2010 MTV Movie Award for Best Fight. \n",
      "\n",
      " Which thriller film did Beyoncé star in with Ali Larter? \n",
      "\n",
      " Obsessed. \n",
      "\n",
      " 703\n"
     ]
    }
   ],
   "source": [
    "q_no = 200\n",
    "x = df_qas[['Question','context_no','q_no','Answer_start','Answer_text','is_impossible']]\n",
    "print(df_contxt['context'][x['context_no'][q_no]],'\\n\\n',\n",
    "      x['Question'][q_no],'\\n\\n',\n",
    "      x['Answer_text'][q_no],'\\n\\n',\n",
    "      x['Answer_start'][q_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132 1132\n"
     ]
    }
   ],
   "source": [
    "y = TextBlob(df_contxt['context'][x['context_no'][q_no]]).sentences\n",
    "k = len(df_contxt['context'][x['context_no'][q_no]])\n",
    "c = -1\n",
    "for i in y:\n",
    "#     print('\\n',i,len(i))\n",
    "    c += len(i)+1\n",
    "print(c,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé further expanded her acting career, starring as blues singer Etta James in the 2008 musical biopic, Cadillac Records. Her performance in the film received praise from critics, and she garnered several nominations for her portrayal of James, including a Satellite Award nomination for Best Supporting Actress, and a NAACP Image Award nomination for Outstanding Supporting Actress. Beyoncé donated her entire salary from the film to Phoenix House, an organization of rehabilitation centers for heroin addicts around the country. On January 20, 2009, Beyoncé performed James' \"At Last\" at the First Couple's first inaugural ball. Beyoncé starred opposite Ali Larter and Idris Elba in the thriller, Obsessed. She played Sharon Charles, a mother and wife who learns of a woman's obsessive behavior over her husband. Although the film received negative reviews from critics, the movie did well at the US box office, grossing $68 million—$60 million more than Cadillac Records—on a budget of $20 million. The fight scene finale between Sharon and the character played by Ali Larter also won the 2010 MTV Movie Award for Best Fight.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title_no', 'context_no', 'q_no', 'q_id', 'Question', 'Answer_text',\n",
       "       'Answer_start', 'is_impossible'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'title_no', 'context_no', 'context'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contxt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I am Prince.\")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = TextBlob('I am Prince.')\n",
    "p[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
