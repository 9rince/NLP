{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\princ3\\anaconda3\\envs\\tfconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = Word2Vec.load('model.bin')    # word embedding\n",
    "# char_vec = Word2Vec.load('model_c.bin')  # charector embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contxt = pd.read_pickle('./input/squad_contxt.pkl') # context\n",
    "df_qas = pd.read_pickle('./input/squad_qas.pkl')       # question and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep_data():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,contxt = df_contxt,qas = df_qas, word_e = word_vec):\n",
    "        \n",
    "        self.contxt = contxt\n",
    "        self.qas = qas\n",
    "        self.char_e = char_e\n",
    "        self.word_e = word_e\n",
    "\n",
    "    def C2V(self,passage):   # this function converts context 2 vector with <EOS> tag\n",
    "        tb_p = TextBlob(passage)\n",
    "        p2v = []\n",
    "        for i in tb_p.sentences:\n",
    "            words = TextBlob(str(i)+\" E-O-S\").words\n",
    "            for j in words:\n",
    "                p2v.append(word_vec[j])\n",
    "        return np.array(p2v)\n",
    "    \n",
    "    def QA2V(self,question_no):  # this function converts question 2 vector\n",
    "        tb_a = TextBlob(self)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_models():\n",
    "    \"\"\"\n",
    "        It's a modified version of normal GRU\n",
    "    \"\"\"\n",
    "    def __init__(self,time_steps,init_state,input_size,tag,\n",
    "                 output_size,question=None,final_mem=None,input_seq=None):\n",
    "        \n",
    "        # inputs required for sequential memory vectors e_i \n",
    "        self.time_steps = time_steps              # equal to max no concepts\n",
    "        self.init_state = init_state              # initial secondary input ideally zero tensor\n",
    "        self.input_seq = input_seq                # input seq to be evaluated\n",
    "        self.input_size = input_size              # size of input vector \n",
    "        self.output_size = output_size            # size of output required\n",
    "        \n",
    "        # inputs required for Answer modules\n",
    "        self.question = question\n",
    "        self.final_mem = final_mem\n",
    "        self.word_weight = tf.get_variable(\"word_w_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.word_bias = tf.get_variable(\"word_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "        \n",
    "        # parameters of gru\n",
    "        self.W_z,self.W_r,self.W_h = tf.get_variable(\"update_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"reset_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64),tf.get_variable(\"out_w_{}\".format(tag),[output_size,input_size],dtype=tf.float64)\n",
    "        self.U_z,self.U_r,self.U_h = tf.get_variable(\"update_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"reset_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64),tf.get_variable(\"out_u_{}\".format(tag),[output_size,output_size],dtype=tf.float64)\n",
    "        self.b_z,self.b_r,self.b_h = tf.get_variable(\"update_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"reset_b_{}\".format(tag),[output_size,1],dtype=tf.float64),tf.get_variable(\"out_b_{}\".format(tag),[output_size,1],dtype=tf.float64)\n",
    "    \n",
    "    \"\"\" Normal GRU unit \"\"\"\n",
    "    def gru_unit(self,h_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations \n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "#         h_t = (self.scalar_values[index]*h_t) + ((1-self.scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.gru_unit(h_prev = h_t,out = out,steps = steps) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    it's a modified GRU !!!\n",
    "    \"\"\"\n",
    "    def mod_gru_unit(self,h_prev,steps,scalar_values,out=[],index=0):\n",
    "#         print(index)\n",
    "        input_vector = self.input_seq[index]\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        h_t = (scalar_values[index]*h_t) + ((1-scalar_values[index])*h_prev)\n",
    "        out.append(h_t)\n",
    "        index += 1\n",
    "        if steps-index == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.mod_gru_unit(h_prev = h_t,out = out,steps = steps,\n",
    "                                     scalar_values=scalar_values,index=index) \n",
    "        \n",
    "    \"\"\" It's a hybrid GRU for answer module \"\"\"\n",
    "    def answer_gru_unit(self,h_prev,word_prev,steps,out=[]):\n",
    "        index = steps - self.time_steps \n",
    "        print(index)\n",
    "#         print(np.shape(word_prev),np.shape(self.question))\n",
    "        input_vector = tf.concat([word_prev,self.question],axis=0)\n",
    "        # operations\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(self.W_z,input_vector)+tf.matmul(self.U_z,h_prev)+self.b_z)\n",
    "        r_t = tf.nn.sigmoid(tf.matmul(self.W_r,input_vector)+tf.matmul(self.U_r,h_prev)+self.b_r)\n",
    "        h_t = tf.multiply(z_t,h_prev)+tf.multiply(1.-z_t,tf.nn.sigmoid(tf.matmul(self.W_h,input_vector)+tf.matmul(self.U_h,tf.multiply(r_t,h_prev))+self.b_h))\n",
    "        word_pred = tf.nn.softmax(tf.matmul(self.word_weight,h_t)+self.word_bias)\n",
    "#         print(h_t)\n",
    "#         print(word_pred)\n",
    "        out.append(word_pred)\n",
    "        self.time_steps -= 1\n",
    "        if self.time_steps == 0:\n",
    "            return(out)\n",
    "        else:\n",
    "            return self.answer_gru_unit(h_prev = h_t,word_prev = word_pred,out = out,steps = steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMN_QA():\n",
    "    \"\"\"\n",
    "    the word vectors have size 100\n",
    "    the max no of words in a sentence is 120\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.MAX_P_WORDS = 120       # max no of words in a passage\n",
    "        self.WORD_VEC_LEN = 100      # word vector length\n",
    "        self.MAX_Q_WORDS = 10        # max no of words in question\n",
    "        self.MAX_NO_CONCEPTS = 5      # max no of concepts\n",
    "        \n",
    "        # variables and placeholders\n",
    "        self.Passage = tf.placeholder(shape=(self.MAX_P_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64)\n",
    "        self.EOS_Tag = tf.placeholder(tf.float64)\n",
    "        self.Question = tf.placeholder(shape=(self.MAX_Q_WORDS,self.WORD_VEC_LEN,1),dtype = tf.float64) #sequence for question\n",
    "        self.Answer = tf.placeholder(tf.float64)\n",
    "        \n",
    "        # weigts for scalar kernel and memory vector\n",
    "        self.W_b = tf.get_variable(\"W_b\",shape=(100,100),dtype=tf.float64)\n",
    "        self.W_1 = tf.get_variable(\"W_1\",shape=(200,702),dtype=tf.float64)\n",
    "        self.b_1 = tf.get_variable(\"b_1\",shape=(200,1),dtype=tf.float64)\n",
    "        self.W_2 = tf.get_variable(\"W_2\",shape=(1,200),dtype=tf.float64)\n",
    "        self.b_2 = tf.get_variable(\"b_2\",shape=(1,1),dtype=tf.float64)\n",
    "        \n",
    "        # initial memory state\n",
    "        self.memory = tf.placeholder(shape=(100,1),dtype=tf.float64)\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        # question module \n",
    "        Q_module = gru_models(time_steps=self.MAX_Q_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Question,tag=1)\n",
    "        Q_out = Q_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_Q_WORDS,out=[])\n",
    "        \n",
    "        self.question = Q_out[-1] # final representation of question\n",
    "        #passage module\n",
    "        P_module = gru_models(time_steps=self.MAX_P_WORDS,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Passage,tag=2)\n",
    "        P_out = P_module.gru_unit(h_prev=np.zeros([self.WORD_VEC_LEN,1]),steps=self.MAX_P_WORDS,out=[])\n",
    "#         print(len(P_out))\n",
    "        #episodic memory module\n",
    "        concepts = P_out[:3]  # selected E-O-S tags from P_out\n",
    "        epi_mod = gru_models(time_steps=2,init_state=np.zeros([self.WORD_VEC_LEN,1]),\n",
    "                              input_size=100,output_size=100,input_seq=self.Passage,tag=3)\n",
    "        y = self.epi_mem_mod(concepts,len(concepts),epi_mod,[])\n",
    "        print(y)\n",
    "        return y\n",
    "    \n",
    "    def epi_mem_mod(self,concepts,no_of_iterations,mode,mem_states=[]):\n",
    "        scalar_vector = []\n",
    "        for i in concepts:\n",
    "            scalar_vector.append(self.scalar_gate_value(i))\n",
    "        \n",
    "        concepts_out = mode.mod_gru_unit(h_prev = self.memory,steps=len(concepts),scalar_values=scalar_vector,\n",
    "                          out=[])\n",
    "        self.memory = concepts_out[-1]\n",
    "        mem_states.append(concepts_out[-1])\n",
    "#         print(no_of_iterations)\n",
    "        if no_of_iterations == 0:\n",
    "            print(mem_states)\n",
    "            return mem_states\n",
    "        else:\n",
    "            self.epi_mem_mod(concepts,no_of_iterations-1,\n",
    "                        mode,mem_states)\n",
    "            \n",
    "    def scalar_gate_value(self,concept):  # debugged and perfect\n",
    "        z_vector = tf.concat((concept,self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.question)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.multiply(concept,self.memory)),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.question),axis=0)\n",
    "        z_vector = tf.concat((z_vector,concept-self.memory),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.question))),axis=0)\n",
    "        z_vector = tf.concat((z_vector,tf.matmul(tf.transpose(concept),tf.matmul(self.W_b,self.memory))),axis=0)\n",
    "        g_1 =  tf.nn.tanh(tf.add(tf.matmul(self.W_1,z_vector),self.b_1))\n",
    "        g_scalar =  tf.nn.sigmoid(tf.add(tf.matmul(self.W_2,g_1),self.b_2))\n",
    "        return g_scalar\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'add_939:0' shape=(100, 1) dtype=float64>, <tf.Tensor 'add_969:0' shape=(100, 1) dtype=float64>, <tf.Tensor 'add_999:0' shape=(100, 1) dtype=float64>, <tf.Tensor 'add_1029:0' shape=(100, 1) dtype=float64>]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = DMN_QA()\n",
    "    x.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA2V(context_no,question_no):\n",
    "    passage = TextBlob(df_contxt['context'][context_no])\n",
    "    question = TextBlob(df_qas['Question'][question_no])\n",
    "    if df_qas['is_impossible'][question_no]==False:\n",
    "        answer = TextBlob(df_qas['Answer_text'][question_no])\n",
    "        beginning = passage[:df_qas['Answer_start'][question_no]]\n",
    "        end = passage[df_qas['Answer_start'][question_no]+len(answer):]  # verified\n",
    "        \n",
    "        \n",
    "#         print(answer.words,'\\n',len(answer.words),'\\n',len(beginning.words),'\\n',len(end.words))\n",
    "    print(len(passage.words),'\\n',len(beginning.words),'\\n',len(answer.words),'\\n',len(end.words))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA2V(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob(str(TextBlob(df_contxt['context'][1]).sentences[0])+\" E-O-S\").words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(value=np.random.random(size=(100,1)),shape=(100,1))\n",
    "y = tf.constant(value=np.random.random(size=(100,1)),shape=(100,1))\n",
    "z = tf.tensordot(tf.transpose(x),y,axes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Tensordot_3:0' shape=(1, 1) dtype=float64>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
